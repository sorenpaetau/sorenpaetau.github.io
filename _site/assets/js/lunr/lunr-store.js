var store = [{
        "title": "Welcome to Jekyll!",
        "excerpt":"You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.   Jekyll requires blog post files to be named according to the following format:   YEAR-MONTH-DAY-title.MARKUP   Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and MARKUP is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.   Jekyll also offers powerful support for code snippets:   def print_hi(name)   puts \"Hi, #{name}\" end print_hi('Tom') #=&gt; prints 'Hi, Tom' to STDOUT.  Check out the Jekyll docs for more info on how to get the most out of Jekyll. File all bugs/feature requests at Jekyll’s GitHub repo. If you have questions, you can ask them on Jekyll Talk.   ","categories": ["jekyll","update"],
        "tags": [],
        "url": "/jekyll/update/2024/07/03/welcome-to-jekyll/",
        "teaser": null
      },{
        "title": "",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/projects/dead/",
        "teaser": null
      },{
        "title": "Current",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/projects/current/",
        "teaser": null
      },{
        "title": "D.e.a.D",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/projects/dead/",
        "teaser": null
      },{
        "title": "Current and Divet",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/projects/cd/",
        "teaser": null
      },{
        "title": "LLM-Powered Procurement Analytics Pipeline",
        "excerpt":"Problem. Procurement data is messy and domain-specific.  Approach. Multi-agent pipeline (Profiler → Retriever → Analyst → Fact-Checker → LaTeX Writer).  Impact. Cut analyst time by ~60%; improved decision-readiness in pilot.   (Add screenshots/GIFs below—WebP preferred, &lt;1MB each.)  ","categories": [],
        "tags": ["LLM","LangChain","OpenAI","LaTeX"],
        "url": "/projects/llm-procurement-pipeline/",
        "teaser": null
      },{
        "title": "Boiling Classification with CNN",
        "excerpt":"TLDR;  Under the guidance of Dr. Corbetta and Dr. Khasin we explored characteristics of accelerometer data in noisy environment to classify  ","categories": [],
        "tags": [],
        "url": "/projects/spotify/",
        "teaser": null
      },{
        "title": "Assorted Research Projects",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/projects/research/",
        "teaser": null
      },{
        "title": "Spotify User Analysis",
        "excerpt":"TLDR;  With public spotify datasets, self (pre-GPT) implemented algorithms (C45, KNN, etc.) were used to deduce user listening habits. A formal report was then reported and made in LaTeX. Steps included data pre-processing, algorithm development and real-world connection to data-driven conclusions.   In this project me and four peers used public datasets on Spotify user listening habits in order to draw a variety of conclusions about user behavior and listening habits. The technical details of this project  ","categories": [],
        "tags": [],
        "url": "/projects/spotify/",
        "teaser": null
      }]
